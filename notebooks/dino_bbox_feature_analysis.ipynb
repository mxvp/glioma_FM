{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/maxvpuyv/anaconda3/envs/brain/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/maxvpuyv/anaconda3/envs/brain/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 501/501 [14:52<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DINO bbox features to /oak/stanford/groups/ogevaert/maxvpuyv/projects/brain/data/features/dino_pdgm_bbox_features_1e4lr150000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- SETTINGS ---\n",
    "DINO_MODEL_NAME = \"facebook/dinov2-base\"\n",
    "CHECKPOINT_PATH = \"/oak/stanford/groups/ogevaert/maxvpuyv/projects/brain/runs/dino_bbox_4batch/checkpoints/checkpoint_final.pt\"\n",
    "PDGM_DIR = \"/oak/stanford/groups/ogevaert/data/brain_mri_tumor_project/UCSF-PDGM-v3\"\n",
    "METADATA_CSV = \"/oak/stanford/groups/ogevaert/maxvpuyv/projects/brain/data/metadata/PGDM/UCSF-PDGM-metadata_v2.csv\"\n",
    "SAVE_PATH = \"/oak/stanford/groups/ogevaert/maxvpuyv/projects/brain/data/features/dino_pdgm_bbox_features_1e4lr150000.npz\"\n",
    "CROP_SIZE = (80, 96)  # (height, width)\n",
    "MARGIN = [10, 10]     # (height, width)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- Projection Head definition ---\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim=256):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(in_dim, out_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(out_dim, out_dim)\n",
    "        )\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.proj(x)\n",
    "\n",
    "# --- Load DINO backbone and projection head ---\n",
    "processor = AutoImageProcessor.from_pretrained(DINO_MODEL_NAME)\n",
    "vit = AutoModel.from_pretrained(DINO_MODEL_NAME).to(DEVICE)\n",
    "proj_head = ProjectionHead(vit.config.hidden_size).to(DEVICE)\n",
    "\n",
    "ckpt = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "vit.load_state_dict(ckpt[\"backbone\"])\n",
    "proj_head.load_state_dict(ckpt[\"head\"])\n",
    "vit.eval()\n",
    "proj_head.eval()\n",
    "\n",
    "# --- Helper: Crop to tumor bbox + margin for 2D slice ---\n",
    "def crop_slice_to_bbox_with_margin(img_slice, mask_slice, margin, crop_size):\n",
    "    if np.sum(mask_slice) == 0:\n",
    "        # No tumor, center crop\n",
    "        h, w = img_slice.shape\n",
    "        ch, cw = crop_size\n",
    "        y0 = max(0, (h - ch) // 2)\n",
    "        x0 = max(0, (w - cw) // 2)\n",
    "        return img_slice[y0:y0+ch, x0:x0+cw]\n",
    "    coords = np.array(np.where(mask_slice > 0))\n",
    "    ymin, xmin = coords.min(axis=1)\n",
    "    ymax, xmax = coords.max(axis=1)\n",
    "    ymin = max(0, ymin - margin[0])\n",
    "    ymax = min(img_slice.shape[0] - 1, ymax + margin[0])\n",
    "    xmin = max(0, xmin - margin[1])\n",
    "    xmax = min(img_slice.shape[1] - 1, xmax + margin[1])\n",
    "    img_crop = img_slice[ymin:ymax+1, xmin:xmax+1]\n",
    "    # Resize to crop_size\n",
    "    img_crop = resize(img_crop, crop_size, order=1, mode='constant', anti_aliasing=True)\n",
    "    return img_crop\n",
    "\n",
    "# --- Preprocessing helper ---\n",
    "def preprocess_slice(slice_2d):\n",
    "    # Normalize and convert to uint8\n",
    "    slice_2d = np.uint8(255 * np.clip(slice_2d, 0, 1))\n",
    "    # DINO expects 3 channels; stack if needed\n",
    "    if slice_2d.ndim == 2:\n",
    "        slice_2d = np.stack([slice_2d]*3, axis=-1)\n",
    "    return processor(images=slice_2d, return_tensors=\"pt\")[\"pixel_values\"].squeeze(0)\n",
    "\n",
    "# --- Feature extraction ---\n",
    "features, case_ids = [], []\n",
    "case_dirs = sorted([d for d in os.listdir(PDGM_DIR) if d.startswith(\"UCSF-PDGM-\")])\n",
    "\n",
    "for case_folder in tqdm(case_dirs):\n",
    "    case_path = os.path.join(PDGM_DIR, case_folder)\n",
    "    num4 = case_folder.split(\"-\")[-1].split(\"_\")[0]\n",
    "    file_case_id = f\"UCSF-PDGM-{num4}\"\n",
    "    t1c_path = os.path.join(case_path, f\"{file_case_id}_T1c_bias.nii.gz\")\n",
    "    mask_path = os.path.join(case_path, f\"{file_case_id}_tumor_segmentation.nii.gz\")\n",
    "    if not (os.path.exists(t1c_path) and os.path.exists(mask_path)):\n",
    "        continue\n",
    "\n",
    "    img = nib.load(t1c_path).get_fdata().astype(np.float32)\n",
    "    mask = nib.load(mask_path).get_fdata().astype(np.uint8)\n",
    "    img = img / (np.max(img) + 1e-8)\n",
    "    slice_embeds = []\n",
    "    for i in range(img.shape[2]):\n",
    "        slice_2d = img[:, :, i]\n",
    "        mask_2d = mask[:, :, i]\n",
    "        # Crop to tumor bbox + margin, then resize\n",
    "        slice_2d_crop = crop_slice_to_bbox_with_margin(slice_2d, mask_2d, MARGIN, CROP_SIZE)\n",
    "        if np.std(slice_2d_crop) < 1e-5:\n",
    "            continue\n",
    "        input_tensor = preprocess_slice(slice_2d_crop).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            embed = vit(input_tensor.unsqueeze(0)).last_hidden_state[:, 0, :]\n",
    "            proj = proj_head(embed)\n",
    "            slice_embeds.append(proj.cpu().numpy().squeeze())\n",
    "    if len(slice_embeds) == 0:\n",
    "        continue\n",
    "    case_embed = np.mean(np.stack(slice_embeds), axis=0)\n",
    "    features.append(case_embed)\n",
    "    case_ids.append(file_case_id)\n",
    "\n",
    "features = np.stack(features)\n",
    "np.savez(SAVE_PATH, features=features, case_ids=np.array(case_ids))\n",
    "print(f\"Saved DINO bbox features to {SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.72      0.81        78\n",
      "           1       0.44      0.81      0.57        21\n",
      "\n",
      "    accuracy                           0.74        99\n",
      "   macro avg       0.68      0.76      0.69        99\n",
      "weighted avg       0.83      0.74      0.76        99\n",
      "\n",
      "ROC AUC: 0.8467643467643468\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Load features and metadata ---\n",
    "data = np.load(SAVE_PATH, allow_pickle=True)\n",
    "X = data[\"features\"]\n",
    "case_ids = data[\"case_ids\"]\n",
    "meta = pd.read_csv(METADATA_CSV).set_index(\"ID\")\n",
    "\n",
    "# --- Standardize case_ids to match metadata index (three digits) ---\n",
    "case_ids_fixed = np.array([f\"UCSF-PDGM-{int(cid.split('-')[-1]):03d}\" for cid in case_ids])\n",
    "\n",
    "# --- Filter to only cases present in metadata ---\n",
    "valid_mask = np.isin(case_ids_fixed, meta.index)\n",
    "X = X[valid_mask]\n",
    "case_ids_fixed = case_ids_fixed[valid_mask]\n",
    "\n",
    "# --- Prepare labels for IDH status ---\n",
    "idh_status = meta.loc[case_ids_fixed, \"IDH\"].values\n",
    "labels = np.array([0 if str(v).strip().lower() == \"wildtype\" else 1 for v in idh_status])\n",
    "\n",
    "# --- Train/test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# --- Train regularized logistic regression classifier ---\n",
    "clf = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = clf.predict(X_test)\n",
    "y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Logistic Regression Classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/maxvpuyv/anaconda3/envs/brain/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.86        78\n",
      "           1       0.44      0.33      0.38        21\n",
      "\n",
      "    accuracy                           0.77        99\n",
      "   macro avg       0.63      0.61      0.62        99\n",
      "weighted avg       0.75      0.77      0.76        99\n",
      "\n",
      "ROC AUC: 0.7087912087912088\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Oversample minority class in training set ---\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# --- Train Random Forest classifier ---\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "y_prob_rf = clf_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest Classification report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column ID not found in metadata.\n",
      "Saved t-SNE for Sex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53247/1707480134.py:32: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved t-SNE for Age at MRI\n",
      "Saved t-SNE for WHO CNS Grade\n",
      "Saved t-SNE for Final pathologic diagnosis (WHO 2021)\n",
      "Saved t-SNE for MGMT status\n",
      "Saved t-SNE for MGMT index\n",
      "Saved t-SNE for 1p/19q\n",
      "Saved t-SNE for IDH\n",
      "Saved t-SNE for 1-dead 0-alive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53247/1707480134.py:32: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved t-SNE for OS\n",
      "Saved t-SNE for EOR\n",
      "Saved t-SNE for Biopsy prior to imaging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53247/1707480134.py:32: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved t-SNE for BraTS21 ID\n",
      "Saved t-SNE for BraTS21 Segmentation Cohort\n",
      "Saved t-SNE for BraTS21 MGMT Cohort\n",
      "All t-SNE plots saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- t-SNE Visualization ---\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "columns = [\n",
    "    \"ID\", \"Sex\", \"Age at MRI\", \"WHO CNS Grade\", \"Final pathologic diagnosis (WHO 2021)\",\n",
    "    \"MGMT status\", \"MGMT index\", \"1p/19q\", \"IDH\", \"1-dead 0-alive\", \"OS\", \"EOR\",\n",
    "    \"Biopsy prior to imaging\", \"BraTS21 ID\", \"BraTS21 Segmentation Cohort\", \"BraTS21 MGMT Cohort\"\n",
    "]\n",
    "\n",
    "outdir_tsne = \"/oak/stanford/groups/ogevaert/maxvpuyv/projects/brain/data/tsne_plots/PDGM_dino_bbox\"\n",
    "os.makedirs(outdir_tsne, exist_ok=True)\n",
    "\n",
    "for column in columns:\n",
    "    try:\n",
    "        values = meta.loc[case_ids_fixed, column].values\n",
    "    except KeyError:\n",
    "        print(f\"Column {column} not found in metadata.\")\n",
    "        continue\n",
    "\n",
    "    values_str = np.array([str(v) if pd.notna(v) else \"NA\" for v in values])\n",
    "\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    for val in np.unique(values_str):\n",
    "        idx = values_str == val\n",
    "        plt.scatter(X_tsne[idx, 0], X_tsne[idx, 1], label=str(val), alpha=0.7, s=20)\n",
    "    plt.legend(markerscale=2, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.title(f\"t-SNE colored by {column}\")\n",
    "    plt.xlabel(\"t-SNE-1\")\n",
    "    plt.ylabel(\"t-SNE-2\")\n",
    "    plt.tight_layout()\n",
    "    fname = f\"tsne_{column.replace(' ', '_').replace('/', '_')}.png\"\n",
    "    plt.savefig(os.path.join(outdir_tsne, fname))\n",
    "    plt.close()\n",
    "    print(f\"Saved t-SNE for {column}\")\n",
    "\n",
    "print(\"All t-SNE plots saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/maxvpuyv/anaconda3/envs/brain/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/scratch/users/maxvpuyv/anaconda3/envs/brain/lib/python3.9/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column ID not found in metadata.\n",
      "Saved UMAP for Sex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53247/308477083.py:25: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved UMAP for Age at MRI\n",
      "Saved UMAP for WHO CNS Grade\n",
      "Saved UMAP for Final pathologic diagnosis (WHO 2021)\n",
      "Saved UMAP for MGMT status\n",
      "Saved UMAP for MGMT index\n",
      "Saved UMAP for 1p/19q\n",
      "Saved UMAP for IDH\n",
      "Saved UMAP for 1-dead 0-alive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53247/308477083.py:25: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved UMAP for OS\n",
      "Saved UMAP for EOR\n",
      "Saved UMAP for Biopsy prior to imaging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53247/308477083.py:25: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved UMAP for BraTS21 ID\n",
      "Saved UMAP for BraTS21 Segmentation Cohort\n",
      "Saved UMAP for BraTS21 MGMT Cohort\n",
      "All UMAP plots saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- UMAP Visualization ---\n",
    "reducer = umap.UMAP(random_state=42)\n",
    "X_umap = reducer.fit_transform(X_scaled)\n",
    "\n",
    "outdir_umap = \"/oak/stanford/groups/ogevaert/maxvpuyv/projects/brain/data/umap_plots/PDGM_dino_bbox\"\n",
    "os.makedirs(outdir_umap, exist_ok=True)\n",
    "\n",
    "for column in columns:\n",
    "    try:\n",
    "        values = meta.loc[case_ids_fixed, column].values\n",
    "    except KeyError:\n",
    "        print(f\"Column {column} not found in metadata.\")\n",
    "        continue\n",
    "\n",
    "    values_str = np.array([str(v) if pd.notna(v) else \"NA\" for v in values])\n",
    "\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    for val in np.unique(values_str):\n",
    "        idx = values_str == val\n",
    "        plt.scatter(X_umap[idx, 0], X_umap[idx, 1], label=str(val), alpha=0.7, s=20)\n",
    "    plt.legend(markerscale=2, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.title(f\"UMAP colored by {column}\")\n",
    "    plt.xlabel(\"UMAP-1\")\n",
    "    plt.ylabel(\"UMAP-2\")\n",
    "    plt.tight_layout()\n",
    "    fname = f\"umap_{column.replace(' ', '_').replace('/', '_')}.png\"\n",
    "    plt.savefig(os.path.join(outdir_umap, fname))\n",
    "    plt.close()\n",
    "    print(f\"Saved UMAP for {column}\")\n",
    "\n",
    "print(\"All UMAP plots saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
